% We are implementing a multiple object motion tracking system that
% MathWorks developed. Our initial/personal implmentation can be found in
% Tests/videoRendering

% Using Kalman Filter and Motion Based tracking to determine and track
% vehicles

%function runs video detection with the assitance of mini helper functions
function MotionBasedMultiObjectTracking()
% Create new object to analyze
videoObj = setupSystem();

% Creates an empty array of structs with properties to track
trackArr = initializeTracks(); % Create an empty array of tracks.

nextId = 1; % ID of the next track

% Detection and Vehicle count for every frame in the video
while hasFrame(videoObj.reader)
       % Stores a single frame of the video
    currFrame = readFrame(videoObj.reader);
    % Performs image filtering and blob analysis, then stores the centroids,
    % bboxes and the filtered Image
    [centroids, bboxes, filteredImage] = detectObjects(currFrame);
    % Predicts the new location of deteced objects
    predictNewLocations();
    % This function decides whether or not to use the predicted location
    % based on confidence of detection and minimized cost
    [assignments, unassignedTracks, unassignedDetections] = ...
        detectionToTrackAssignment();

    % Updates unidentified tracks as they move
    updateAssignedTracks();
    % Updates unidentified tracks as they move
    updateUnassignedTracks();
    % delete tracks for objects that leave frame
    deleteLostTracks();
    % Creates new tracks for objects that enter frame
    createNewTracks();

    displayTrackingResults();
end

%%%%%%%%%%%%% FUNCTION DEFINITIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Initial function to setup environment
    function videoObj = setupSystem()
        % Constructor function that initializes a new object to analyze
    
        % Video Reader method
        videoObj.reader = VideoReader('TrafficTest2.mp4');

        % We are using 2 video player methods, one for the dislaying and one 
        % for the foreground detector
        videoObj.filteredPlayer = vision.VideoPlayer('Position', [740, 400, 700, 400]);
        videoObj.videoPlayer = vision.VideoPlayer('Position', [20, 400, 700, 400]);

        % Now we need to just add the methods for the Foreground Detector and
        % Blob Analysis of the images
        videoObj.detector = vision.ForegroundDetector('NumGaussians', 3, ...
            'NumTrainingFrames', 40, 'MinimumBackgroundRatio', 0.7);

        videoObj.blobAnalyser = vision.BlobAnalysis('BoundingBoxOutputPort', true, ...
            'AreaOutputPort', true, 'CentroidOutputPort', true, ...
            'MinimumBlobArea', 400);
    end

% Function creates an empty array of structs with properties to track
    function trackArr = initializeTracks()
        % create an empty array of tracks
        trackArr = struct(...
            'id', {}, ...
            'bbox', {}, ...
            'kalmanFilter', {}, ...
            'age', {}, ...
            'totalVisibleCount', {}, ...
            'consecutiveInvisibleCount', {});
    end

% Function performs image filtering and blob analysis
    function [centroids, bboxes, filteredImage] = detectObjects(currFrame)

        % Detect foreground.
        filteredImage = videoObj.detector.step(currFrame);

        % Apply morphological operations to remove noise and fill in holes.
        filteredImage = imopen(filteredImage, strel('rectangle', [3,3]));
        filteredImage = imclose(filteredImage, strel('rectangle', [15, 15]));
        filteredImage = imfill(filteredImage, 'holes');

        % Perform blob analysis to find connected components.
        [~, centroids, bboxes] = videoObj.blobAnalyser.step(filteredImage);
    end

% This function is responsible for predicting where the object will be of
% it was covered by an external object (bridge, overpass, etc)
    function predictNewLocations()
        for i = 1:length(trackArr)
            bbox = trackArr(i).bbox;

            % Predict the current location of the track.
            predictedCentroid = predict(trackArr(i).kalmanFilter);

            % Shift the bounding box so that its center is at
            % the predicted location.
            predictedCentroid = int32(predictedCentroid) - bbox(3:4) / 2;
            trackArr(i).bbox = [predictedCentroid, bbox(3:4)];
        end
    end

% This function decides whether or not to use the predicted location
% based on confidence of detection and minimized cost
    function [assignments, unassignedTracks, unassignedDetections] = ...
            detectionToTrackAssignment()

        nTracks = length(trackArr);
        nDetections = size(centroids, 1);

        % Compute the cost of assigning each detection to each track.
        cost = zeros(nTracks, nDetections);
        for i = 1:nTracks
            cost(i, :) = distance(trackArr(i).kalmanFilter, centroids);
        end

        % Solve the assignment problem.
        costOfNonAssignment = 20;
        [assignments, unassignedTracks, unassignedDetections] = ...
            assignDetectionsToTracks(cost, costOfNonAssignment);
    end

% This function updates and corrects the location estimation we make for
% the tracks we detect
% and updates the age of the tracks accordingly
    function updateAssignedTracks()
        numAssignedTracks = size(assignments, 1);
        for i = 1:numAssignedTracks
            trackIdx = assignments(i, 1);
            detectionIdx = assignments(i, 2);
            centroid = centroids(detectionIdx, :);
            bbox = bboxes(detectionIdx, :);

            % Correct the estimate of the object's location
            % using the new detection.
            correct(trackArr(trackIdx).kalmanFilter, centroid);

            % Replace predicted bounding box with detected
            % bounding box.
            trackArr(trackIdx).bbox = bbox;

            % Update track's age.
            trackArr(trackIdx).age = trackArr(trackIdx).age + 1;

            % Update visibility.
            trackArr(trackIdx).totalVisibleCount = ...
                trackArr(trackIdx).totalVisibleCount + 1;
            trackArr(trackIdx).consecutiveInvisibleCount = 0;
        end
    end
% This function makes sure unassigned tracks are invisible
    function updateUnassignedTracks()
        for i = 1:length(unassignedTracks)
            ind = unassignedTracks(i);
            trackArr(ind).age = trackArr(ind).age + 1;
            trackArr(ind).consecutiveInvisibleCount = ...
                trackArr(ind).consecutiveInvisibleCount + 1;
        end
    end

% Function deletes tracks that have been invisible for too many
% consecutive frames
    function deleteLostTracks()
        if isempty(trackArr)
            return;
        end

        invisibleForTooLong = 20;
        ageThreshold = 8;

        % Compute the fraction of the track's age for which it was visible.
        ages = [trackArr(:).age];
        totalVisibleCounts = [trackArr(:).totalVisibleCount];
        visibility = totalVisibleCounts ./ ages;

        % Find the indices of 'lost' tracks.
        lostInds = (ages < ageThreshold & visibility < 0.6) | ...
            [trackArr(:).consecutiveInvisibleCount] >= invisibleForTooLong;

        % Delete lost tracks.
        trackArr = trackArr(~lostInds);
    end
% This function creates new tracks from unassigned detections.
% Assume that any unassigned detection is a start of a new track.
    function createNewTracks()
        centroids = centroids(unassignedDetections, :);
        bboxes = bboxes(unassignedDetections, :);

        for i = 1:size(centroids, 1)

            centroid = centroids(i,:);
            bbox = bboxes(i, :);

            % Create a Kalman filter object.
            kalmanFilter = configureKalmanFilter('ConstantVelocity', ...
                centroid, [200, 50], [100, 25], 100);

            % Create a new track.
            newTrack = struct(...
                'id', nextId, ...
                'bbox', bbox, ...
                'kalmanFilter', kalmanFilter, ...
                'age', 1, ...
                'totalVisibleCount', 1, ...
                'consecutiveInvisibleCount', 0);

            % Add it to the array of tracks.
            trackArr(end + 1) = newTrack;

            % Increment the next id.
            nextId = nextId + 1;
        end
    end
%This function draws a bounding box and label ID for each track ...
% on the video frame and the foreground mask.
%It then displays the frame and the mask in their respective video players
    function displayTrackingResults()
        % Convert the frame and the mask to uint8 RGB.
        currFrame = im2uint8(currFrame);
        filteredImage = uint8(repmat(filteredImage, [1, 1, 3])) .* 255;

        minVisibleCount = 8;
        if ~isempty(trackArr)

            % Noisy detections tend to result in short-lived tracks.
            % Only display tracks that have been visible for more than
            % a minimum number of frames.
            reliableTrackInds = ...
                [trackArr(:).totalVisibleCount] > minVisibleCount;
            reliableTracks = trackArr(reliableTrackInds);

            % Display the objects. If an object has not been detected
            % in this frame, display its predicted bounding box.
            if ~isempty(reliableTracks)
                % Get bounding boxes.
                bboxes = cat(1, reliableTracks.bbox);

                % Get ids.
                ids = int32([reliableTracks(:).id]);

                % Create labels for objects indicating the ones for
                % which we display the predicted rather than the actual
                % location.
                labels = cellstr(int2str(ids'));
                predictedTrackInds = ...
                    [reliableTracks(:).consecutiveInvisibleCount] > 0;
                isPredicted = cell(size(labels));
                isPredicted(predictedTrackInds) = {' predicted'};
                labels = strcat(labels, isPredicted);

                % Draw the objects on the frame.
                currFrame = insertObjectAnnotation(currFrame, 'rectangle', ...
                    bboxes, labels);

                % Draw the objects on the mask.
                filteredImage = insertObjectAnnotation(filteredImage, 'rectangle', ...
                    bboxes, labels);
            end
        end

        % Display the mask and the frame.
        videoObj.filteredPlayer.step(filteredImage);
        videoObj.videoPlayer.step(currFrame);
    end
end